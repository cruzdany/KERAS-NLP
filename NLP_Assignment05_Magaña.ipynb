{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment05_Magaña.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cruzdany/KERAS-NLP/blob/main/NLP_Assignment05_Maga%C3%B1a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slNXYz304EqL"
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "from numpy import *  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqw6MJrF4EqO"
      },
      "source": [
        "df = pd.read_csv('train.csv',encoding='utf-8',error_bad_lines=False, engine=\"python\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Za0XIzXvCwK"
      },
      "source": [
        "\"\"\"import nltk\n",
        "nltk.download('stopwords')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "0o3TzCgnu-C9",
        "outputId": "bcbb7c93-440c-4d68-8b54-b6fccdaed14d"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "def scrub_words(text):\n",
        "    # remove html markup\n",
        "    text=re.sub(\"(<.*?>)\",\"\",text)\n",
        "    \n",
        "    #remove non-ascii and digits\n",
        "    text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
        "  \n",
        "    #remove whitespace\n",
        "    text=text.strip()\n",
        "    return text\n",
        "  \n",
        "#Noise removal, stop word removal, normalizing?\n",
        "def cleanString(s, special_chars = \"\\\":,.@|ðÿœžðÿâœœïÿœžÿºÿÿœžÿ=_\"):\n",
        "    for char in special_chars:\n",
        "        s = s.replace(char, \"\")\n",
        "    s = s.replace(\"\\n\", \"\")\n",
        "    s = scrub_words(s)\n",
        "    tokenizer = TweetTokenizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    cleaned_words = [w for w in tokenizer.tokenize(s) if w not in stop_words]\n",
        "    return \" \".join(cleaned_words), tokenizer\n",
        "\n",
        "def stemWords(sentence):\n",
        "    stemmer, tokenizer = PorterStemmer(), TweetTokenizer()\n",
        "    stemmed_words = [stemmer.stem(w) for w in tokenizer.tokenize(sentence)]\n",
        "    return \" \".join(stemmed_words)\n",
        "    \n",
        "def cleanFrame(frame):\n",
        "    frame['clean_tweet'] = frame.comment_text.apply(cleanString)\n",
        "\n",
        "\n",
        "cleanFrame(df)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(ExplanationWhy edits made username Hardcore M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(D aww He matches background colour I seemingl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Hey man I really trying edit war It guy const...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(MoreI make real suggestions improvement I won...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(You sir hero Any chance remember page, &lt;nltk....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...                                        clean_tweet\n",
              "0  0000997932d777bf  ...  (ExplanationWhy edits made username Hardcore M...\n",
              "1  000103f0d9cfb60f  ...  (D aww He matches background colour I seemingl...\n",
              "2  000113f07ec002fd  ...  (Hey man I really trying edit war It guy const...\n",
              "3  0001b41b1c6bb37e  ...  (MoreI make real suggestions improvement I won...\n",
              "4  0001d958c54c6e35  ...  (You sir hero Any chance remember page, <nltk....\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMX2LOSa4EqT",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "\"\"\"special_chars = r\"[^a-z0-9!@#\\$%\\^\\&\\*_\\-,\\.' ]\"\n",
        "\n",
        "class preprocessing(object):\n",
        "    def __init__(self,special_chars):\n",
        "        self.special_chars = special_chars\n",
        "    def cleanString(self,s):\n",
        "        # remove special chars\n",
        "        if self.special_chars is not None:\n",
        "            s = re.sub(self.special_chars, ' ', s)\n",
        "        s = s.replace(\"\\\\n\", \" \").replace(\"\\n\", \" \")\n",
        "        tokenizer = TweetTokenizer()\n",
        "        # Remove stop words\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        cleaned_words = [w for w in tokenizer.tokenize(s) if w not in stop_words]\n",
        "        return \" \".join(cleaned_words)\n",
        "\n",
        "    def stemWords(self,sentence):\n",
        "        stemmer, tokenizer = PorterStemmer(), TweetTokenizer()\n",
        "        stemmed_words = [stemmer.stem(w) for w in tokenizer.tokenize(sentence)]\n",
        "        return \" \".join(stemmed_words)\n",
        "\n",
        "    def cleanFrame(selfdev,frame):\n",
        "        frame['clean_comment'] = frame.comment_text.apply(selfdev.cleanString)\n",
        "\n",
        "    def stemFrame(selfdev,frame):\n",
        "        frame['stem_comment'] = frame.clean_comment.apply(selfdev.stemWords)\n",
        "\n",
        "Preprocessing=preprocessing(special_chars)\n",
        "Preprocessing.cleanFrame(df)\n",
        "Preprocessing.stemFrame(df)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3dopVRd4EqU"
      },
      "source": [
        "Import Pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U25OiVo4EqV"
      },
      "source": [
        "\"\"\"import pickle\n",
        "toxic_comments = open('../toxic.pickle','rb') \n",
        "df = pickle.load(toxic_comments)\n",
        "df.sample(5)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "AmVxgTg9zzNy",
        "outputId": "6a1328a5-366f-4087-c065-cc157fc56d5f"
      },
      "source": [
        "import re\n",
        "special_chars = r\"[^0-9!@#\\$%\\^\\&\\*_\\-']\"\n",
        "def Cleaning(tweet,special_chars):\n",
        "    tweet = re.sub(\"\\d+\", \"\", tweet)\n",
        "    tweet=re.sub(\"h[\\S]+//[\\S]+\", \"\", tweet)\n",
        "    tweet=re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", tweet)\n",
        "    tweet=tweet.lower()\n",
        "    for char in special_chars:\n",
        "        tweet = tweet.replace(char, \"\")    \n",
        "    tweet=tweet.split(\" \")\n",
        "    return ' '.join(tweet)\n",
        "Cleaned=[]\n",
        "for t in df[\"comment_text\"]:\n",
        "    Cleaned.append(Cleaning(t,special_chars))\n",
        "df['text_generation'] = Cleaned\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>text_generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(ExplanationWhy edits made username Hardcore M...</td>\n",
              "      <td>explanationwhy the edits made under my usernam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(D aww He matches background colour I seemingl...</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Hey man I really trying edit war It guy const...</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(MoreI make real suggestions improvement I won...</td>\n",
              "      <td>morei cant make any real suggestions on improv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(You sir hero Any chance remember page, &lt;nltk....</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...                                    text_generation\n",
              "0  0000997932d777bf  ...  explanationwhy the edits made under my usernam...\n",
              "1  000103f0d9cfb60f  ...  daww he matches this background colour im seem...\n",
              "2  000113f07ec002fd  ...  hey man im really not trying to edit war its j...\n",
              "3  0001b41b1c6bb37e  ...  morei cant make any real suggestions on improv...\n",
              "4  0001d958c54c6e35  ...  you sir are my hero any chance you remember wh...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_kLJ9_s4EqW",
        "outputId": "9df50b7e-0df2-4cb1-8a2c-a1652b63369c"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
              "       'insult', 'identity_hate', 'clean_tweet', 'text_generation'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-CSUJ-s6DFw"
      },
      "source": [
        "y = df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfNHXInq4EqX",
        "outputId": "3c4fbe0c-5455-4598-fa5e-93f2bd135622"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text_generation, y, test_size=0.2,\n",
        "                                                    random_state=np.random)\n",
        "print(X_train.shape, X_test.shape, len(y_train), len(y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(127656,) (31915,) 127656 31915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFoxaUSY4EqY",
        "outputId": "10eea1cc-8eab-489a-a697-2117e5350a57"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "maxlen=400\n",
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "V_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "V_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
        "print(V_train.shape,V_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(127656, 400) (31915, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_k5EWJ84EqZ"
      },
      "source": [
        "def getModel():\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    embed_size = 128\n",
        "    x = Embedding(max_features, embed_size)(inp)\n",
        "    x = LSTM(30, return_sequences=True,name='lstm_layer')(x)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(20, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(6, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mabMuv8c4EqZ",
        "outputId": "167205e9-c900-4a01-ac14-019a1948b7fa"
      },
      "source": [
        "model = getModel()\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "file_path=\"../weights_base.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=2)\n",
        "\n",
        "\n",
        "callbacks_list = [checkpoint, early] #early\n",
        "model.fit(V_train,y_train,  batch_size=batch_size, epochs=epochs, \n",
        "          validation_split=0.1, callbacks=callbacks_list)\n",
        "\n",
        "model.load_weights(file_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3591/3591 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.8830\n",
            "Epoch 00001: val_loss improved from inf to 0.05595, saving model to ../weights_base.best.hdf5\n",
            "3591/3591 [==============================] - 795s 221ms/step - loss: 0.0975 - accuracy: 0.8830 - val_loss: 0.0560 - val_accuracy: 0.9945\n",
            "Epoch 2/3\n",
            "3591/3591 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9929\n",
            "Epoch 00002: val_loss did not improve from 0.05595\n",
            "3591/3591 [==============================] - 794s 221ms/step - loss: 0.0591 - accuracy: 0.9929 - val_loss: 0.0561 - val_accuracy: 0.9945\n",
            "Epoch 3/3\n",
            "3591/3591 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9934\n",
            "Epoch 00003: val_loss improved from 0.05595 to 0.05547, saving model to ../weights_base.best.hdf5\n",
            "3591/3591 [==============================] - 799s 222ms/step - loss: 0.0535 - accuracy: 0.9934 - val_loss: 0.0555 - val_accuracy: 0.9945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1XXy-5R4EqZ",
        "outputId": "e496a829-ab09-40c3-af74-c8c34e0a477e"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "y_pred = model.predict(V_test)\n",
        "print(classification_report(y_test,y_pred.round(),digits=6))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.838139  0.716869  0.772776      3041\n",
            "           1   0.000000  0.000000  0.000000       334\n",
            "           2   0.789842  0.786171  0.788002      1721\n",
            "           3   0.000000  0.000000  0.000000        93\n",
            "           4   0.702811  0.664978  0.683371      1579\n",
            "           5   0.000000  0.000000  0.000000       281\n",
            "\n",
            "   micro avg   0.789084  0.650163  0.712919      7049\n",
            "   macro avg   0.388465  0.361336  0.374025      7049\n",
            "weighted avg   0.711851  0.650163  0.678849      7049\n",
            " samples avg   0.061053  0.058741  0.057187      7049\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQyw7abaFQyn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}